
# ğŸš—Real-Time Parking Availability Tracker

## ğŸ“– Introduction

The **Real-Time Parking Availability Tracker** is a scalable system designed to monitor and analyze parking slot availability in real-time.  
It uses **Apache Kafka** for event streaming, **Apache Spark Streaming** for real-time processing, and **MySQL** for persistent storage and historical batch analytics.

---

## ğŸš€ Features

- ğŸ”´ **Real-Time Monitoring:** Track live parking availability.  
- ğŸ”— **Multiple Data Sources:** Sensor devices, mobile apps, external systems.  
- âš¡ **Event-Driven Architecture:** Using Apache Kafka.  
- ğŸ”¥ **Real-Time Processing:** Spark Structured Streaming.  
- ğŸ—‚ï¸ **Persistent Storage:** MySQL database for historical analysis.  
- ğŸ“Š **Batch Analytics:** Spark SQL queries over historical data.  

---

## ğŸ› ï¸ Installation and Setup

### Prerequisites

- Python 3.8 or above  
- Apache Kafka and Zookeeper  
- Apache Spark  
- MySQL Server  
- Git (optional for cloning)

### Install Python Dependencies

```bash
pip install kafka-python pyspark mysql-connector-python
```

---

## ğŸ–¥ï¸ Setup Guide

### 1. Start Kafka and Zookeeper

```bash
# Start Zookeeper
bin/zookeeper-server-start.sh config/zookeeper.properties

# Start Kafka Broker
bin/kafka-server-start.sh config/server.properties
```

### 2. Create Kafka Topics

```bash
bin/kafka-topics.sh --create --topic sensor-topic --bootstrap-server localhost:9092
bin/kafka-topics.sh --create --topic app-topic --bootstrap-server localhost:9092
bin/kafka-topics.sh --create --topic external-topic --bootstrap-server localhost:9092
```

### 3. Setup MySQL Database

```bash
# Login to MySQL
mysql -u root -p

# Inside MySQL shell
source sql/parkingdb.sql;
```

### 4. Run Kafka Producers

```bash
# In separate terminals
python kafka_producer/produce_sensor.py
python kafka_producer/produce_app.py
python kafka_producer/produce_external.py
```

### 5. Run Spark Streaming Job

```bash
spark-submit spark_streaming/spark_streaming.py
```

### 6. Run Spark Batch Job (Optional)

```bash
spark-submit spark_batch/spark_batch.py
```

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ kafka_producer/
â”‚   â”œâ”€â”€ produce_app.py
â”‚   â”œâ”€â”€ produce_external.py
â”‚   â””â”€â”€ produce_sensor.py
â”‚
â”œâ”€â”€ spark_streaming/
â”‚   â””â”€â”€ spark_streaming.py
â”‚
â”œâ”€â”€ spark_batch/
â”‚   â””â”€â”€ spark_batch.py
â”‚
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ parkingdb.sql
â”‚
â””â”€â”€ README.md
```

---

## ğŸ“¢ Important Commands Summary

| Purpose                       | Command                                                                 |
|-------------------------------|-------------------------------------------------------------------------|
| Start Zookeeper               | `bin/zookeeper-server-start.sh config/zookeeper.properties`            |
| Start Kafka Broker            | `bin/kafka-server-start.sh config/server.properties`                   |
| Create Kafka Topics           | `bin/kafka-topics.sh --create --topic <topic-name> --bootstrap-server localhost:9092` |
| Run Kafka Producer (Sensor)   | `python kafka_producer/produce_sensor.py`                              |
| Run Kafka Producer (App)      | `python kafka_producer/produce_app.py`                                 |
| Run Kafka Producer (External) | `python kafka_producer/produce_external.py`                            |
| Run Spark Streaming Job       | `spark-submit spark_streaming/spark_streaming.py`                      |
| Run Spark Batch Job           | `spark-submit spark_batch/spark_batch.py`                              |

---

## ğŸ Final Notes

- Ensure all services (**Kafka**, **Zookeeper**, **MySQL**) are running before starting producers and consumers.  
- Modify connection parameters (like MySQL username/password or Kafka broker address) in scripts if needed.  
- Extend the project easily by adding more producers or real-time analytics logic!
